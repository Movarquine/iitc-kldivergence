By MH Gencer


Go to 'code.py' above for the Python script (requires Python 3.9 or higher). See below for a short explanation. 


# Integrated Information Theory of Consciousness (IITC)
IITC is a relatively new theory of consciousness proposed by Giulio Tononi (2008, 2014, 2016). The theory's main goal is to establish the foundations for a mathematical framework in which we can answer the question of why we are conscious. In the framework IITC offers, consciousness results from highly integrated informational processes that can be specified by using a set of well-defined mathematical concepts. The hope is to open new avenues for both empirical and purely mathematical research on individually necessary and jointly sufficient conditions for having conscious experience.


# Kullback-Leibler Divergence (KLD)
KLD is one of the statistical concepts used in IITC. Specifically, IITC uses KLD to conceptualize the difference between what the conscious entity generates as output (i.e., conscious experience) and what its brain (or any other physical substrate of consciousness) takes as input (e.g., sense-data), both construed as probability distributions. KLD proves helpful here because it quantifies how much one probability distribution differs from another probability distribution. From an information-theoretic perspective, KLD calculates how many bits of information (nats) are lost in the process where the received input is being turned into the generated output, which makes it a handy tool in the IITC framework. For related reasons, KLD has been argued to be the best measure of integrated information. In the interactive graph generated by 'code.py', KLD is stated using the standard notation KL(P || Q), measured in terms of nats.

# References


